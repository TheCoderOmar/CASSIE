{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepspeech\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_deepspeech_model(model_path, scorer_path):\n",
    "    model = deepspeech.Model(model_path)\n",
    "    model.enableExternalScorer(scorer_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_directory(folder_path, file_extension, keyword=None):\n",
    "    if keyword:\n",
    "        return sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension) and keyword in f])\n",
    "    else:\n",
    "        return sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcription_data(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_transcription(transcription_data, sample_name):\n",
    "    return next((item['transcription'] for item in transcription_data if item['sample_name'] == sample_name), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import time\n",
    "def transcribe_audio_with_time(model, wav_file_path):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load the audio file using pydub\n",
    "    audio = AudioSegment.from_wav(wav_file_path)\n",
    "    \n",
    "    # Convert to mono and set the sample rate to 16000 Hz\n",
    "    audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "\n",
    "    # Convert the audio to a numpy array with int16 data type\n",
    "    raw_data = np.array(audio.get_array_of_samples(), dtype=np.int16)\n",
    "    \n",
    "    # DeepSpeech expects a bytes object\n",
    "    buffer = raw_data.tobytes()\n",
    "    \n",
    "    # Use DeepSpeech model to perform transcription\n",
    "    result = model.stt(buffer)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    transcription_time = end_time - start_time\n",
    "\n",
    "    return result, transcription_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_csv_pandas(csv_file_path, results):\n",
    "    df = pd.DataFrame(results, columns=[\"File\", \"Whisper Output\", \"Correct Transcription\", \"Cosine Similarity\", \"Transcription Time\"])\n",
    "    df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(reference, hypothesis):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([reference, hypothesis])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cos_sim = cosine_similarity(vectors)[0, 1]\n",
    "    return cos_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_and_save_to_csv_pandas(audio_folder_path, transcription_folder_path, model, csv_file_path):\n",
    "    wav_files = get_files_in_directory(audio_folder_path, '.wav')\n",
    "    json_files = get_files_in_directory(transcription_folder_path, '.json', keyword='_transcription')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSON files\", unit=\"file\"):\n",
    "        json_path = os.path.join(transcription_folder_path, json_file)\n",
    "        transcription_data = load_transcription_data(json_path)\n",
    "        is_with_pause = \"_with_pause\" in json_file\n",
    "        base_name = json_file.replace(\"_transcription_with_pause\", \"\").replace(\"_transcription\", \"\").replace(\".json\", \"\")\n",
    "        \n",
    "        for i in tqdm(range(1, 6), desc=f\"Processing {json_file}\", leave=False, unit=\"sample\"):\n",
    "            if is_with_pause:\n",
    "                wav_file = f\"{base_name}_with_pause_{i}.wav\"\n",
    "            else:\n",
    "                wav_file = f\"{base_name}_{i}.wav\"\n",
    "            \n",
    "            wav_path = os.path.join(audio_folder_path, wav_file)\n",
    "            \n",
    "            if not os.path.exists(wav_path):\n",
    "                print(f\"Audio file {wav_file} not found.\")\n",
    "                continue\n",
    "            \n",
    "            sample_name = f\"sample_{i}\"\n",
    "            correct_transcription = get_matching_transcription(transcription_data, sample_name)\n",
    "            \n",
    "            if not correct_transcription:\n",
    "                print(f\"No matching transcription found for {wav_file} in {json_file}.\")\n",
    "                continue\n",
    "            \n",
    "            # Transcribe the audio and measure time using DeepSpeech\n",
    "            whisper_output, transcription_time = transcribe_audio_with_time(model, wav_path)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            cosine_sim = calculate_cosine_similarity(correct_transcription, whisper_output)\n",
    "            \n",
    "            # Store result\n",
    "            results.append([wav_file, whisper_output, correct_transcription, cosine_sim, transcription_time])\n",
    "    \n",
    "    # Write results to CSV\n",
    "    write_results_to_csv_pandas(csv_file_path, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = \"../Voices/Female American (Nova)/no pause\"\n",
    "transcription_folder_path1 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path1 = \"processed/Nova_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path2 = \"../Voices/Female American (Nova)/with pause/\"\n",
    "transcription_folder_path2 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path2 = \"processed/Nova_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path3 = \"../Voices/Female American (Nova) with Noise/no pause/\"\n",
    "transcription_folder_path3 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path3 = \"processed/Nova_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path4 = \"../Voices/Female American (Nova) with Noise/with pause/\"\n",
    "transcription_folder_path4 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path4 = \"processed/Nova_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path5 = \"../Voices/Female British (Madelyn)/no pause/\"\n",
    "transcription_folder_path5 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path5 = \"processed/Madelyn_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path6 = \"../Voices/Female British (Madelyn)/with pause/\"\n",
    "transcription_folder_path6 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path6 = \"processed/Madelyn_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path7 = \"../Voices/Female British (Madelyn) with Noise/with pause/\"\n",
    "transcription_folder_path7 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path7 = \"processed/Madelyn_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path8 = \"../Voices/Female British (Madelyn) with Noise/no pause/\"\n",
    "transcription_folder_path8 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path8 = \"processed/Madelyn_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path9 = \"../Voices/Male American (Michael)/no pause/\"\n",
    "transcription_folder_path9 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path9 = \"processed/Michael_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path10 = \"../Voices/Male American (Michael)/with pause/\"\n",
    "transcription_folder_path10 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path10 = \"processed/Michael_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path11 = \"../Voices/Male American (Michael) with Noise/no pause/\"\n",
    "transcription_folder_path11 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path11 = \"processed/Michael_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path12 = \"../Voices/Male American (Michael) with Noise/with pause/\"\n",
    "transcription_folder_path12 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path12 = \"processed/Michael_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path13 = \"../Voices/Male British (Oliver)/no pause/\"\n",
    "transcription_folder_path13 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path13 = \"processed/Oliver_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path14 = \"../Voices/Male British (Oliver)/with pause/\"\n",
    "transcription_folder_path14 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path14 = \"processed/Oliver_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path15 = \"../Voices/Male British (Oliver) with Noise/no pause/\"\n",
    "transcription_folder_path15 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path15 = \"processed/Oliver_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path16 = \"../Voices/Male British (Oliver) with Noise/with pause/\"\n",
    "transcription_folder_path16 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path16 = \"processed/Oliver_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../../deepspeech-0.9.3-models.pbmm\"\n",
    "scorer_path = \"../../../deepspeech-0.9.3-models.scorer\"\n",
    "model = load_deepspeech_model(model_path, scorer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files:   0%|          | 0/5 [00:00<?, ?file/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: b'\\x0c\\x00\\x0b\\x00\\x0c\\x00\\n\\x00\\x0b\\x00\\x08\\x00\\x06\\x00\\x08\\x00\\x08\\x00\\x07\\x00\\x06\\x00\\x08\\x00\\t\\x00\\n\\x00\\n\\x00\\n\\x00\\x08\\x00\\x08\\x00\\x08\\x00\\n\\x00\\x0c\\x00\\r\\x00\\x0b\\x00\\n\\x00\\x0b\\x00\\n\\x00\\x0b\\x00",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprocess_files_and_save_to_csv_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtranscription_folder_path1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file_path1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m process_files_and_save_to_csv_pandas(folder_path2,transcription_folder_path2, model, csv_file_path2)\n\u001b[0;32m      3\u001b[0m process_files_and_save_to_csv_pandas(folder_path3,transcription_folder_path3, model, csv_file_path3)\n",
      "Cell \u001b[1;32mIn[91], line 33\u001b[0m, in \u001b[0;36mprocess_files_and_save_to_csv_pandas\u001b[1;34m(audio_folder_path, transcription_folder_path, model, csv_file_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Transcribe the audio and measure time using DeepSpeech\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m whisper_output, transcription_time \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_with_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity\u001b[39;00m\n\u001b[0;32m     36\u001b[0m cosine_sim \u001b[38;5;241m=\u001b[39m calculate_cosine_similarity(correct_transcription, whisper_output)\n",
      "Cell \u001b[1;32mIn[88], line 20\u001b[0m, in \u001b[0;36mtranscribe_audio_with_time\u001b[1;34m(model, wav_file_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m buffer \u001b[38;5;241m=\u001b[39m raw_data\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Use DeepSpeech model to perform transcription\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     23\u001b[0m transcription_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Conda\\envs\\deeepspeech\\lib\\site-packages\\deepspeech\\__init__.py:162\u001b[0m, in \u001b[0;36mModel.stt\u001b[1;34m(self, audio_buffer)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstt\u001b[39m(\u001b[38;5;28mself\u001b[39m, audio_buffer):\n\u001b[0;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Use the DeepSpeech model to perform Speech-To-Text.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    :type: str\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeepspeech\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpeechToText\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Conda\\envs\\deeepspeech\\lib\\site-packages\\deepspeech\\impl.py:175\u001b[0m, in \u001b[0;36mSpeechToText\u001b[1;34m(aCtx, aBuffer)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSpeechToText\u001b[39m(aCtx, aBuffer):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpeechToText\u001b[49m\u001b[43m(\u001b[49m\u001b[43maCtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maBuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: b'\\x0c\\x00\\x0b\\x00\\x0c\\x00\\n\\x00\\x0b\\x00\\x08\\x00\\x06\\x00\\x08\\x00\\x08\\x00\\x07\\x00\\x06\\x00\\x08\\x00\\t\\x00\\n\\x00\\n\\x00\\n\\x00\\x08\\x00\\x08\\x00\\x08\\x00\\n\\x00\\x0c\\x00\\r\\x00\\x0b\\x00\\n\\x00\\x0b\\x00\\n\\x00\\x0b\\x00"
     ]
    }
   ],
   "source": [
    "process_files_and_save_to_csv_pandas(folder_path1,transcription_folder_path1, model, csv_file_path1)\n",
    "process_files_and_save_to_csv_pandas(folder_path2,transcription_folder_path2, model, csv_file_path2)\n",
    "process_files_and_save_to_csv_pandas(folder_path3,transcription_folder_path3, model, csv_file_path3)\n",
    "process_files_and_save_to_csv_pandas(folder_path4,transcription_folder_path4, model, csv_file_path4)\n",
    "process_files_and_save_to_csv_pandas(folder_path5,transcription_folder_path5, model, csv_file_path5)\n",
    "process_files_and_save_to_csv_pandas(folder_path6,transcription_folder_path6, model, csv_file_path6)\n",
    "process_files_and_save_to_csv_pandas(folder_path7,transcription_folder_path7, model, csv_file_path7)\n",
    "process_files_and_save_to_csv_pandas(folder_path8,transcription_folder_path8, model, csv_file_path8)\n",
    "process_files_and_save_to_csv_pandas(folder_path9,transcription_folder_path9, model, csv_file_path9)\n",
    "process_files_and_save_to_csv_pandas(folder_path10,transcription_folder_path10, model, csv_file_path10)\n",
    "process_files_and_save_to_csv_pandas(folder_path11,transcription_folder_path11, model, csv_file_path11)\n",
    "process_files_and_save_to_csv_pandas(folder_path12,transcription_folder_path12, model, csv_file_path12)\n",
    "process_files_and_save_to_csv_pandas(folder_path13,transcription_folder_path13, model, csv_file_path13)\n",
    "process_files_and_save_to_csv_pandas(folder_path14,transcription_folder_path14, model, csv_file_path14)\n",
    "process_files_and_save_to_csv_pandas(folder_path15,transcription_folder_path15, model, csv_file_path15)\n",
    "process_files_and_save_to_csv_pandas(folder_path16,transcription_folder_path16, model, csv_file_path16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeepspeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
