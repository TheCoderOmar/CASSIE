{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import whisper\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whisper_model(model_size=\"base\"):\n",
    "    return whisper.load_model(model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_directory(folder_path, file_extension):\n",
    "    return sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load transcription data from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcription_data(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get matching transcription from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_transcription(transcription_data, sample_name):\n",
    "    return next((item['transcription'] for item in transcription_data if item['sample_name'] == sample_name), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe audio and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_with_time(model, wav_file_path):\n",
    "    start_time = time.time()\n",
    "    result = model.transcribe(wav_file_path)\n",
    "    end_time = time.time()\n",
    "    transcription_time = end_time - start_time\n",
    "    return result['text'], transcription_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Word Error Rate (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(reference, hypothesis):\n",
    "    return jiwer.wer(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Character Error Rate (CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(reference, hypothesis):\n",
    "    return jiwer.cer(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Sentence Error Rate (SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ser(reference_sentences, hypothesis_sentences):\n",
    "    incorrect_sentences = sum([ref != hyp for ref, hyp in zip(reference_sentences, hypothesis_sentences)])\n",
    "    return incorrect_sentences / len(reference_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, hypothesis):\n",
    "    reference = [reference.split()]\n",
    "    hypothesis = hypothesis.split()\n",
    "    return sentence_bleu(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_levenshtein(reference, hypothesis):\n",
    "    return Levenshtein.distance(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(reference, hypothesis):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([reference, hypothesis])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cos_sim = cosine_similarity(vectors)[0, 1]\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to write results to a CSV file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_csv_pandas(csv_file_path, results):\n",
    "    df = pd.DataFrame(results, columns=[\"File\", \"Whisper Output\", \"Correct Transcription\", \"WER\", \"CER\", \"SER\", \"BLEU\", \"Levenshtein Distance\", \"Cosine Similarity\", \"Transcription Time\"])\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process files and save the result to CSV with tqdm progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_and_save_to_csv_pandas(folder_path, model, csv_file_path):\n",
    "    # Get list of files\n",
    "    wav_files = get_files_in_directory(folder_path, '.wav')\n",
    "    json_files = get_files_in_directory(folder_path, '.json')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSON files\", unit=\"file\"):  # Add progress bar here\n",
    "        # Load the transcription data from JSON\n",
    "        json_path = os.path.join(folder_path, json_file)\n",
    "        transcription_data = load_transcription_data(json_path)\n",
    "        \n",
    "        base_name = json_file.replace(\"_transcription.json\", \"\")\n",
    "        \n",
    "        for i in tqdm(range(1, 6), desc=f\"Processing {json_file}\", leave=False, unit=\"sample\"):  # Inner loop progress bar\n",
    "            wav_file = f\"{base_name}_{i}.wav\"\n",
    "            wav_path = os.path.join(folder_path, wav_file)\n",
    "            \n",
    "            if not os.path.exists(wav_path):\n",
    "                print(f\"Audio file {wav_file} not found.\")\n",
    "                continue\n",
    "            \n",
    "            sample_name = f\"sample_{i}\"\n",
    "            correct_transcription = get_matching_transcription(transcription_data, sample_name)\n",
    "            \n",
    "            if not correct_transcription:\n",
    "                print(f\"No matching transcription found for {wav_file} in {json_file}.\")\n",
    "                continue\n",
    "            \n",
    "            # Transcribe the audio and measure time\n",
    "            whisper_output, transcription_time = transcribe_audio_with_time(model, wav_path)\n",
    "            \n",
    "            # Calculate WER, CER, SER, BLEU, Levenshtein Distance, and Cosine Similarity\n",
    "            wer = calculate_wer(correct_transcription, whisper_output)\n",
    "            cer = calculate_cer(correct_transcription, whisper_output)\n",
    "            ser = calculate_ser([correct_transcription], [whisper_output])\n",
    "            bleu = calculate_bleu(correct_transcription, whisper_output)\n",
    "            levenshtein_distance = calculate_levenshtein(correct_transcription, whisper_output)\n",
    "            cosine_sim = calculate_cosine_similarity(correct_transcription, whisper_output)\n",
    "            \n",
    "            # Store result in the list\n",
    "            results.append([wav_file, whisper_output, correct_transcription, wer, cer, ser, bleu, levenshtein_distance, cosine_sim, transcription_time])\n",
    "    \n",
    "    # Write results to CSV using pandas\n",
    "    write_results_to_csv_pandas(csv_file_path, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Conda\\envs\\whisper\\lib\\site-packages\\whisper\\__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = load_whisper_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = \"../Voices/Male British (Oliver)\"\n",
    "csv_file_path1 = \"data/Oliver_base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = \"../Voices/Male British (Oliver)\"\n",
    "csv_file_path1 = \"data/Oliver_base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path2 = \"../Voices/Female British (Madelyn)\"\n",
    "csv_file_path2 = \"data/Madelyn_base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path3 = \"../Voices/Female American (Nava)\"\n",
    "csv_file_path3 = \"data/Nava_base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path4 = \"../Voices/Male American (Michael)\"\n",
    "csv_file_path4 = \"data/Michael_base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the FP16 warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files: 100%|██████████| 5/5 [00:44<00:00,  8.89s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:44<00:00,  8.91s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:44<00:00,  8.99s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:44<00:00,  8.95s/file]\n"
     ]
    }
   ],
   "source": [
    "process_files_and_save_to_csv_pandas(folder_path1, model, csv_file_path1)\n",
    "process_files_and_save_to_csv_pandas(folder_path2, model, csv_file_path2)\n",
    "process_files_and_save_to_csv_pandas(folder_path3, model, csv_file_path3)\n",
    "process_files_and_save_to_csv_pandas(folder_path4, model, csv_file_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='noisy_phone_call6.wav'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "# Load your audio file (e.g., clean audio)\n",
    "audio = AudioSegment.from_wav(\"../Voices/Female American (Nava)/10_words_sample_1.wav\")\n",
    "\n",
    "# Simulate phone call effect by bandpass filtering (300Hz to 3400Hz)\n",
    "phone_call_audio = audio.low_pass_filter(3400).high_pass_filter(300)\n",
    "\n",
    "# Generate white noise\n",
    "def generate_white_noise(duration_ms, sample_rate, volume_db=-50):  # Further reduced volume\n",
    "    num_samples = int((duration_ms / 1000.0) * sample_rate)\n",
    "    samples = np.random.normal(0, 1, num_samples)\n",
    "    samples = samples * (10 ** (volume_db / 20))  # Set volume\n",
    "    return AudioSegment(\n",
    "        samples.tobytes(),\n",
    "        frame_rate=sample_rate,\n",
    "        sample_width=2,  # 16-bit audio\n",
    "        channels=1       # Mono\n",
    "    )\n",
    "\n",
    "# Get properties of the original audio\n",
    "sample_rate = phone_call_audio.frame_rate\n",
    "duration_ms = len(phone_call_audio)\n",
    "\n",
    "# Generate white noise for the same duration as the audio\n",
    "noise = generate_white_noise(duration_ms, sample_rate)\n",
    "\n",
    "# Apply a low-pass filter to the noise to soften it\n",
    "noise = noise.low_pass_filter(3000)  # Remove harsh higher frequencies\n",
    "\n",
    "# Mix noise with the phone call audio at a lower ratio for clarity\n",
    "mix_ratio = 0.05  # Further reduce the mix ratio\n",
    "noisy_audio = phone_call_audio.overlay(noise - 30 * (1 - mix_ratio), position=0)  # Further reduce noise volume\n",
    "\n",
    "# Apply a high-pass filter to the noisy audio to enhance clarity\n",
    "noisy_audio = noisy_audio.high_pass_filter(300)\n",
    "\n",
    "# Export the noisy phone call audio\n",
    "noisy_audio.export(\"noisy_phone_call6.wav\", format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
