{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import whisper\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whisper_model(model_size,device):\n",
    "    return whisper.load_model(model_size,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_directory(folder_path, file_extension, keyword=None):\n",
    "    if keyword:\n",
    "        return sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension) and keyword in f])\n",
    "    else:\n",
    "        return sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load transcription data from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcription_data(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get matching transcription from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_transcription(transcription_data, sample_name):\n",
    "    return next((item['transcription'] for item in transcription_data if item['sample_name'] == sample_name), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe audio and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_with_time(model, wav_file_path,device=\"cuda\"):\n",
    "    start_time = time.time()\n",
    "    result = model.transcribe(wav_file_path)\n",
    "    end_time = time.time()\n",
    "    transcription_time = end_time - start_time\n",
    "    return result['text'], transcription_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Word Error Rate (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(reference, hypothesis):\n",
    "    return jiwer.wer(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Character Error Rate (CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(reference, hypothesis):\n",
    "    return jiwer.cer(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Sentence Error Rate (SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ser(reference_sentences, hypothesis_sentences):\n",
    "    incorrect_sentences = sum([ref != hyp for ref, hyp in zip(reference_sentences, hypothesis_sentences)])\n",
    "    return incorrect_sentences / len(reference_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, hypothesis):\n",
    "    reference = [reference.split()]\n",
    "    hypothesis = hypothesis.split()\n",
    "    return sentence_bleu(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_levenshtein(reference, hypothesis):\n",
    "    return Levenshtein.distance(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(reference, hypothesis):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([reference, hypothesis])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cos_sim = cosine_similarity(vectors)[0, 1]\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to write results to a CSV file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_csv_pandas(csv_file_path, results):\n",
    "    # Adjusting the DataFrame to match the actual number of columns in results\n",
    "    df = pd.DataFrame(results, columns=[\"File\", \"Whisper Output\", \"Correct Transcription\", \"Cosine Similarity\", \"Transcription Time\"])\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process files and save the result to CSV with tqdm progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_and_save_to_csv_pandas(audio_folder_path, transcription_folder_path, model, csv_file_path):\n",
    "    # Get list of audio files and transcription JSON files from their respective directories\n",
    "    wav_files = get_files_in_directory(audio_folder_path, '.wav')\n",
    "    json_files = get_files_in_directory(transcription_folder_path, '.json', keyword='_transcription')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSON files\", unit=\"file\"):  # Add progress bar here\n",
    "        # Load the transcription data from JSON\n",
    "        json_path = os.path.join(transcription_folder_path, json_file)\n",
    "        transcription_data = load_transcription_data(json_path)\n",
    "        \n",
    "        # Determine if the file is \"with pause\" or \"no pause\"\n",
    "        is_with_pause = \"_with_pause\" in json_file\n",
    "        \n",
    "        # Create the base name based on the transcription file\n",
    "        base_name = json_file.replace(\"_transcription_with_pause\", \"\").replace(\"_transcription\", \"\").replace(\".json\", \"\")\n",
    "        \n",
    "        #print(f\"Processing {json_file} with base name: {base_name}, with pause: {is_with_pause}\")\n",
    "        \n",
    "        for i in tqdm(range(1, 6), desc=f\"Processing {json_file}\", leave=False, unit=\"sample\"):  # Inner loop progress bar\n",
    "            # Construct the expected audio file name\n",
    "            if is_with_pause:\n",
    "                wav_file = f\"{base_name}_with_pause_{i}.wav\"\n",
    "            else:\n",
    "                wav_file = f\"{base_name}_{i}.wav\"\n",
    "            \n",
    "            wav_path = os.path.join(audio_folder_path, wav_file)\n",
    "            \n",
    "            #print(f\"Looking for audio file: {wav_file}\")\n",
    "            \n",
    "            if not os.path.exists(wav_path):\n",
    "                print(f\"Audio file {wav_file} not found.\")\n",
    "                continue\n",
    "            \n",
    "            sample_name = f\"sample_{i}\"\n",
    "            correct_transcription = get_matching_transcription(transcription_data, sample_name)\n",
    "            \n",
    "            if not correct_transcription:\n",
    "                print(f\"No matching transcription found for {wav_file} in {json_file}.\")\n",
    "                continue\n",
    "            \n",
    "            # Transcribe the audio and measure time\n",
    "            whisper_output, transcription_time = transcribe_audio_with_time(model, wav_path, device=\"cuda\")\n",
    "            \n",
    "            # Calculate only cosine similarity (or other metrics as needed)\n",
    "            cosine_sim = calculate_cosine_similarity(correct_transcription, whisper_output)\n",
    "            \n",
    "            # Store result in the list\n",
    "            results.append([wav_file, whisper_output, correct_transcription, cosine_sim, transcription_time])\n",
    "    \n",
    "    # Write results to CSV using pandas\n",
    "    write_results_to_csv_pandas(csv_file_path, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 461M/461M [02:49<00:00, 2.85MiB/s]\n",
      "c:\\Conda\\envs\\whisper\\lib\\site-packages\\whisper\\__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = load_whisper_model(\"small.en\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = \"../Voices/Female American (Nova)/no pause\"\n",
    "transcription_folder_path1 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path1 = \"processed/Nova_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path2 = \"../Voices/Female American (Nova)/with pause/\"\n",
    "transcription_folder_path2 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path2 = \"processed/Nova_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path3 = \"../Voices/Female American (Nova) with Noise/no pause/\"\n",
    "transcription_folder_path3 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path3 = \"processed/Nova_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path4 = \"../Voices/Female American (Nova) with Noise/with pause/\"\n",
    "transcription_folder_path4 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path4 = \"processed/Nova_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path5 = \"../Voices/Female British (Madelyn)/no pause/\"\n",
    "transcription_folder_path5 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path5 = \"processed/Madelyn_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path6 = \"../Voices/Female British (Madelyn)/with pause/\"\n",
    "transcription_folder_path6 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path6 = \"processed/Madelyn_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path7 = \"../Voices/Female British (Madelyn) with Noise/with pause/\"\n",
    "transcription_folder_path7 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path7 = \"processed/Madelyn_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path8 = \"../Voices/Female British (Madelyn) with Noise/no pause/\"\n",
    "transcription_folder_path8 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path8 = \"processed/Madelyn_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path9 = \"../Voices/Male American (Michael)/no pause/\"\n",
    "transcription_folder_path9 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path9 = \"processed/Michael_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path10 = \"../Voices/Male American (Michael)/with pause/\"\n",
    "transcription_folder_path10 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path10 = \"processed/Michael_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path11 = \"../Voices/Male American (Michael) with Noise/no pause/\"\n",
    "transcription_folder_path11 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path11 = \"processed/Michael_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path12 = \"../Voices/Male American (Michael) with Noise/with pause/\"\n",
    "transcription_folder_path12 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path12 = \"processed/Michael_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path13 = \"../Voices/Male British (Oliver)/no pause/\"\n",
    "transcription_folder_path13 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path13 = \"processed/Oliver_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path14 = \"../Voices/Male British (Oliver)/with pause/\"\n",
    "transcription_folder_path14 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path14 = \"processed/Oliver_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path15 = \"../Voices/Male British (Oliver) with Noise/no pause/\"\n",
    "transcription_folder_path15 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path15 = \"processed/Oliver_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path16 = \"../Voices/Male British (Oliver) with Noise/with pause/\"\n",
    "transcription_folder_path16 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path16 = \"processed/Oliver_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the FP16 warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files: 100%|██████████| 5/5 [00:27<00:00,  5.51s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:27<00:00,  5.44s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:24<00:00,  4.82s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:26<00:00,  5.21s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:24<00:00,  4.83s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:26<00:00,  5.36s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:25<00:00,  5.19s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:23<00:00,  4.74s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:24<00:00,  4.87s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:27<00:00,  5.55s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:23<00:00,  4.72s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:25<00:00,  5.05s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:23<00:00,  4.67s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:26<00:00,  5.22s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:23<00:00,  4.77s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:25<00:00,  5.08s/file]\n"
     ]
    }
   ],
   "source": [
    "process_files_and_save_to_csv_pandas(folder_path1,transcription_folder_path1, model, csv_file_path1)\n",
    "process_files_and_save_to_csv_pandas(folder_path2,transcription_folder_path2, model, csv_file_path2)\n",
    "process_files_and_save_to_csv_pandas(folder_path3,transcription_folder_path3, model, csv_file_path3)\n",
    "process_files_and_save_to_csv_pandas(folder_path4,transcription_folder_path4, model, csv_file_path4)\n",
    "process_files_and_save_to_csv_pandas(folder_path5,transcription_folder_path5, model, csv_file_path5)\n",
    "process_files_and_save_to_csv_pandas(folder_path6,transcription_folder_path6, model, csv_file_path6)\n",
    "process_files_and_save_to_csv_pandas(folder_path7,transcription_folder_path7, model, csv_file_path7)\n",
    "process_files_and_save_to_csv_pandas(folder_path8,transcription_folder_path8, model, csv_file_path8)\n",
    "process_files_and_save_to_csv_pandas(folder_path9,transcription_folder_path9, model, csv_file_path9)\n",
    "process_files_and_save_to_csv_pandas(folder_path10,transcription_folder_path10, model, csv_file_path10)\n",
    "process_files_and_save_to_csv_pandas(folder_path11,transcription_folder_path11, model, csv_file_path11)\n",
    "process_files_and_save_to_csv_pandas(folder_path12,transcription_folder_path12, model, csv_file_path12)\n",
    "process_files_and_save_to_csv_pandas(folder_path13,transcription_folder_path13, model, csv_file_path13)\n",
    "process_files_and_save_to_csv_pandas(folder_path14,transcription_folder_path14, model, csv_file_path14)\n",
    "process_files_and_save_to_csv_pandas(folder_path15,transcription_folder_path15, model, csv_file_path15)\n",
    "process_files_and_save_to_csv_pandas(folder_path16,transcription_folder_path16, model, csv_file_path16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
