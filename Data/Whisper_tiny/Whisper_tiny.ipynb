{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import whisper\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whisper_model(model_size=\"tiny\"):\n",
    "    return whisper.load_model(model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_directory(folder_path, file_extension, keyword=None):\n",
    "    if keyword:\n",
    "        return sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension) and keyword in f])\n",
    "    else:\n",
    "        return sorted([f for f in os.listdir(folder_path) if f.endswith(file_extension)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load transcription data from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcription_data(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get matching transcription from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_transcription(transcription_data, sample_name):\n",
    "    return next((item['transcription'] for item in transcription_data if item['sample_name'] == sample_name), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe audio and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_with_time(model, wav_file_path):\n",
    "    start_time = time.time()\n",
    "    result = model.transcribe(wav_file_path)\n",
    "    end_time = time.time()\n",
    "    transcription_time = end_time - start_time\n",
    "    return result['text'], transcription_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Word Error Rate (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(reference, hypothesis):\n",
    "    return jiwer.wer(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Character Error Rate (CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(reference, hypothesis):\n",
    "    return jiwer.cer(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Sentence Error Rate (SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ser(reference_sentences, hypothesis_sentences):\n",
    "    incorrect_sentences = sum([ref != hyp for ref, hyp in zip(reference_sentences, hypothesis_sentences)])\n",
    "    return incorrect_sentences / len(reference_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, hypothesis):\n",
    "    reference = [reference.split()]\n",
    "    hypothesis = hypothesis.split()\n",
    "    return sentence_bleu(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_levenshtein(reference, hypothesis):\n",
    "    return Levenshtein.distance(reference, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(reference, hypothesis):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([reference, hypothesis])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cos_sim = cosine_similarity(vectors)[0, 1]\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to write results to a CSV file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_csv_pandas(csv_file_path, results):\n",
    "    # Adjusting the DataFrame to match the actual number of columns in results\n",
    "    df = pd.DataFrame(results, columns=[\"File\", \"Whisper Output\", \"Correct Transcription\", \"Cosine Similarity\", \"Transcription Time\"])\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process files and save the result to CSV with tqdm progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_and_save_to_csv_pandas(audio_folder_path, transcription_folder_path, model, csv_file_path):\n",
    "    # Get list of audio files and transcription JSON files from their respective directories\n",
    "    wav_files = get_files_in_directory(audio_folder_path, '.wav')\n",
    "    json_files = get_files_in_directory(transcription_folder_path, '.json', keyword='_transcription')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSON files\", unit=\"file\"):  # Add progress bar here\n",
    "        # Load the transcription data from JSON\n",
    "        json_path = os.path.join(transcription_folder_path, json_file)\n",
    "        transcription_data = load_transcription_data(json_path)\n",
    "        \n",
    "        # Determine if the file is \"with pause\" or \"no pause\"\n",
    "        is_with_pause = \"_with_pause\" in json_file\n",
    "        \n",
    "        # Create the base name based on the transcription file\n",
    "        base_name = json_file.replace(\"_transcription_with_pause\", \"\").replace(\"_transcription\", \"\").replace(\".json\", \"\")\n",
    "        \n",
    "        #print(f\"Processing {json_file} with base name: {base_name}, with pause: {is_with_pause}\")\n",
    "        \n",
    "        for i in tqdm(range(1, 6), desc=f\"Processing {json_file}\", leave=False, unit=\"sample\"):  # Inner loop progress bar\n",
    "            # Construct the expected audio file name\n",
    "            if is_with_pause:\n",
    "                wav_file = f\"{base_name}_with_pause_{i}.wav\"\n",
    "            else:\n",
    "                wav_file = f\"{base_name}_{i}.wav\"\n",
    "            \n",
    "            wav_path = os.path.join(audio_folder_path, wav_file)\n",
    "            \n",
    "            #print(f\"Looking for audio file: {wav_file}\")\n",
    "            \n",
    "            if not os.path.exists(wav_path):\n",
    "                print(f\"Audio file {wav_file} not found.\")\n",
    "                continue\n",
    "            \n",
    "            sample_name = f\"sample_{i}\"\n",
    "            correct_transcription = get_matching_transcription(transcription_data, sample_name)\n",
    "            \n",
    "            if not correct_transcription:\n",
    "                print(f\"No matching transcription found for {wav_file} in {json_file}.\")\n",
    "                continue\n",
    "            \n",
    "            # Transcribe the audio and measure time\n",
    "            whisper_output, transcription_time = transcribe_audio_with_time(model, wav_path)\n",
    "            \n",
    "            # Calculate only cosine similarity (or other metrics as needed)\n",
    "            cosine_sim = calculate_cosine_similarity(correct_transcription, whisper_output)\n",
    "            \n",
    "            # Store result in the list\n",
    "            results.append([wav_file, whisper_output, correct_transcription, cosine_sim, transcription_time])\n",
    "    \n",
    "    # Write results to CSV using pandas\n",
    "    write_results_to_csv_pandas(csv_file_path, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:23<00:00, 3.19MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = load_whisper_model(\"tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = \"../Voices/Female American (Nova)/no pause/\"\n",
    "transcription_folder_path1 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path1 = \"processed/Nova_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path2 = \"../Voices/Female American (Nova)/with pause\"\n",
    "transcription_folder_path2 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path2 = \"processed/Nova_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path3 = \"../Voices/Female American (Nova) with Noise/no pause/\"\n",
    "transcription_folder_path3 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path3 = \"processed/Nova_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path4 = \"../Voices/Female American (Nova) with Noise/with pause\"\n",
    "transcription_folder_path4 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path4 = \"processed/Nova_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path5 = \"../Voices/Female British (Madelyn)/no pause/\"\n",
    "transcription_folder_path5 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path5 = \"processed/Madelyn_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path6 = \"../Voices/Female British (Madelyn)/with pause/\"\n",
    "transcription_folder_path6 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path6 = \"processed/Madelyn_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path7 = \"../Voices/Female British (Madelyn) with Noise/with pause/\"\n",
    "transcription_folder_path7 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path7 = \"processed/Madelyn_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path8 = \"../Voices/Female British (Madelyn) with Noise/no pause/\"\n",
    "transcription_folder_path8 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path8 = \"processed/Madelyn_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path9 = \"../Voices/Male American (Michael)/no pause/\"\n",
    "transcription_folder_path9 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path9 = \"processed/Michael_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path10 = \"../Voices/Male American (Michael)/with pause/\"\n",
    "transcription_folder_path10 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path10 = \"processed/Michael_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path11 = \"../Voices/Male American (Michael) with Noise/no pause/\"\n",
    "transcription_folder_path11 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path11 = \"processed/Michael_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path12 = \"../Voices/Male American (Michael) with Noise/with pause/\"\n",
    "transcription_folder_path12 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path12 = \"processed/Michael_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path13 = \"../Voices/Male British (Oliver)/no pause/\"\n",
    "transcription_folder_path13 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path13 = \"processed/Oliver_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path14 = \"../Voices/Male British (Oliver)/with pause/\"\n",
    "transcription_folder_path14 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path14 = \"processed/Oliver_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path15 = \"../Voices/Male British (Oliver) with Noise/no pause/\"\n",
    "transcription_folder_path15 = \"../Voices/Transcription/no pause\"\n",
    "csv_file_path15 = \"processed/Oliver_Noise_no_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path16 = \"../Voices/Male British (Oliver) with Noise/with pause/\"\n",
    "transcription_folder_path16 = \"../Voices/Transcription/with pause\"\n",
    "csv_file_path16 = \"processed/Oliver_Noise_with_pause.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the FP16 warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.73s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:30<00:00,  6.15s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.77s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:30<00:00,  6.01s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.70s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:30<00:00,  6.07s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:45<00:00,  9.18s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.75s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.77s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:30<00:00,  6.09s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.78s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:30<00:00,  6.05s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.73s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:31<00:00,  6.29s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:28<00:00,  5.68s/file]\n",
      "Processing JSON files: 100%|██████████| 5/5 [00:30<00:00,  6.03s/file]\n"
     ]
    }
   ],
   "source": [
    "process_files_and_save_to_csv_pandas(folder_path1,transcription_folder_path1, model, csv_file_path1)\n",
    "process_files_and_save_to_csv_pandas(folder_path2,transcription_folder_path2, model, csv_file_path2)\n",
    "process_files_and_save_to_csv_pandas(folder_path3,transcription_folder_path3, model, csv_file_path3)\n",
    "process_files_and_save_to_csv_pandas(folder_path4,transcription_folder_path4, model, csv_file_path4)\n",
    "process_files_and_save_to_csv_pandas(folder_path5,transcription_folder_path5, model, csv_file_path5)\n",
    "process_files_and_save_to_csv_pandas(folder_path6,transcription_folder_path6, model, csv_file_path6)\n",
    "process_files_and_save_to_csv_pandas(folder_path7,transcription_folder_path7, model, csv_file_path7)\n",
    "process_files_and_save_to_csv_pandas(folder_path8,transcription_folder_path8, model, csv_file_path8)\n",
    "process_files_and_save_to_csv_pandas(folder_path9,transcription_folder_path9, model, csv_file_path9)\n",
    "process_files_and_save_to_csv_pandas(folder_path10,transcription_folder_path10, model, csv_file_path10)\n",
    "process_files_and_save_to_csv_pandas(folder_path11,transcription_folder_path11, model, csv_file_path11)\n",
    "process_files_and_save_to_csv_pandas(folder_path12,transcription_folder_path12, model, csv_file_path12)\n",
    "process_files_and_save_to_csv_pandas(folder_path13,transcription_folder_path13, model, csv_file_path13)\n",
    "process_files_and_save_to_csv_pandas(folder_path14,transcription_folder_path14, model, csv_file_path14)\n",
    "process_files_and_save_to_csv_pandas(folder_path15,transcription_folder_path15, model, csv_file_path15)\n",
    "process_files_and_save_to_csv_pandas(folder_path16,transcription_folder_path16, model, csv_file_path16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
